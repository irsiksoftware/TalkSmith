[{"body":"Add licensing (e.g., AGPL or a custom restrictive license), CONTRIBUTING.md, and CODEOWNERS for review gates.\n\nAcceptance Criteria:\n- [ ] LICENSE selected and documented\n- [ ] CONTRIBUTING.md and CODEOWNERS enforce PR review\n\nLabels: Area/Docs, Type/chore\nPriority: P2\nDepends on: Initialize repo structure and decision log","number":23,"title":"Repository hygiene: LICENSE, CONTRIBUTING, CODEOWNERS"},{"body":"Document and script model downloads, cache directories, and pin known-good model versions.\n\nAcceptance Criteria:\n- [ ] scripts/prefetch_models.(ps1|sh) with sizes selectable\n- [ ] DECISIONS.md entry describing chosen versions and rationale\n\nLabels: Area/Infra, Type/chore\nPriority: P2\nDepends on: Implement faster-whisper transcribe (GPU)","number":22,"title":"Model cache management and version pinning"},{"body":"Provide a simple redaction pass for obvious PII and include a consent template for recordings.\n\nAcceptance Criteria:\n- [ ] pipeline/redact_pii.py with common patterns (emails, phones) and whitelist file\n- [ ] docs/consent_template.md\n\nLabels: Area/Legal, Area/Docs, Type/feat\nPriority: P2\nDepends on: Export formats: TXT, SRT, VTT, JSON segments","number":21,"title":"PII scrubbing and consent templates"},{"body":"Add structured logging (JSON lines) and robust error handling with retry/backoff on transient errors.\n\nAcceptance Criteria:\n- [ ] logs written per file to data/outputs/<slug>/logs/*.log\n- [ ] Non-zero exit codes on failure; summary at end of batch runs\n\nLabels: Area/Infra, Type/feat\nPriority: P1\nDepends on: Batch transcribe directory with resume capability","number":20,"title":"Logging and error handling"},{"body":"Provide a CUDA-enabled Dockerfile and compose for reproducible GPU runs (Linux).\n\nAcceptance Criteria:\n- [ ] Dockerfile.cuda based on nvidia/cuda, installs deps and models cache\n- [ ] README section for nvidia-container-toolkit setup and docker run --gpus all\n\nLabels: Area/Infra, Type/feat, OS/Linux\nPriority: P2\nDepends on: Create Python environment and lock dependencies","number":19,"title":"Docker (CUDA) for reproducible runs"},{"body":"Add unit tests for exporters and post-processing; e2e test on a short sample WAV.\n\nAcceptance Criteria:\n- [ ] tests/ with pytest; GitHub Actions runs CPU-path tests\n- [ ] Sample audio under data/samples/ with expected outputs\n\nLabels: Area/QA, Type/test\nPriority: P1\nDepends on: Export formats: TXT, SRT, VTT, JSON segments","number":18,"title":"Tests: unit + end-to-end sample"},{"body":"Provide a single entrypoint that guides the user through preprocessing, transcription, diarization, export, and (optional) sync.\n\nAcceptance Criteria:\n- [ ] cli/main.py with subcommands: preprocess, transcribe, diarize, export, batch, plan, sync\n- [ ] README Quickstart with copy-paste commands for Windows & Linux\n\nLabels: Area/Docs, Area/Transcription, Type/feat\nPriority: P1\nDepends on: Configuration system and settings.ini","number":17,"title":"CLI wrapper and Quickstart"},{"body":"Convert segments JSON into a PRD/plan markdown and (optionally) push to Google Docs via API.\n\nAcceptance Criteria:\n- [ ] pipeline/plan_from_transcript.py creates plan.md with Problem/Users/Goals/AC/Risks\n- [ ] scripts/push_to_gdoc.(ps1|sh) (requires creds) to create/update doc\n\nLabels: Area/Export, Type/feat\nPriority: P2\nDepends on: Speaker label post-processing and outline generator","number":16,"title":"Optional: Generate Google Doc plan from transcript"},{"body":"Add rclone-based sync so outputs can be mirrored to a Drive folder your mobile app watches.\n\nAcceptance Criteria:\n- [ ] scripts/sync_to_drive.(ps1|sh) using rclone remote\n- [ ] Document setup for rclone config and a dry-run mode\n\nLabels: Area/Export, Type/feat\nPriority: P2\nDepends on: Export formats: TXT, SRT, VTT, JSON segments","number":15,"title":"Optional: Google Drive sync (rclone)"},{"body":"Centralize settings for models, diarization mode, batch paths, and export options.\n\nAcceptance Criteria:\n- [ ] settings.ini with [Paths], [Models], [Diarization], [Export]\n- [ ] scripts respect env var overrides and CLI flags\n\nLabels: Area/Infra, Type/feat\nPriority: P0\nDepends on: Implement faster-whisper transcribe (GPU)","number":14,"title":"Configuration system and settings.ini"},{"body":"Provide a repeatable benchmark for RTF (speed) and WER (quality) on sample audio.\n\nAcceptance Criteria:\n- [ ] benchmarks/run_benchmarks.(ps1|sh) captures RTF/WER per model size and diarization mode\n- [ ] Report saved to benchmarks/report.csv and benchmarks/report.md\n\nLabels: Area/Benchmarks, Type/feat\nPriority: P2\nDepends on: Multi-GPU parallelism and job scheduler","number":13,"title":"Benchmark suite: throughput and quality"},{"body":"Use both RTX 3060s concurrently. Implement a simple job queue that pins processes to specific GPUs and avoids VRAM contention.\n\nAcceptance Criteria:\n- [ ] scripts/launcher.(ps1|sh) with --gpus 0,1 and worker concurrency\n- [ ] Benchmarks show near-linear throughput vs single-GPU on >1h corpora\n\nLabels: Area/Infra, Area/Transcription, Type/feat\nPriority: P1\nDepends on: Batch transcribe directory with resume capability","number":12,"title":"Multi-GPU parallelism and job scheduler"},{"body":"Improve readability by normalizing speaker IDs (Speaker 1/2/â€¦), merging short utterances, and generating a timestamped outline of key topics.\n\nAcceptance Criteria:\n- [ ] pipeline/postprocess_speakers.py with --normalize-names and --min-utterance-ms\n- [ ] pipeline/outline_from_segments.py outputs outline.md with [HH:MM:SS] anchors\n\nLabels: Area/Diarization, Type/feat\nPriority: P1\nDepends on: Export formats: TXT, SRT, VTT, JSON segments","number":11,"title":"Speaker label post-processing and outline generator"},{"body":"Provide multiple export formats for downstream tools.\n\nAcceptance Criteria:\n- [ ] Exporters produce .txt, .srt, .vtt, .json (segments with timestamps and speakers)\n- [ ] Timecodes validated; unit tests for edge cases (overlapping speech)\n\nLabels: Area/Export, Type/feat\nPriority: P0\nDepends on: Batch transcribe directory with resume capability","number":10,"title":"Export formats: TXT, SRT, VTT, JSON segments"},{"body":"Implement a batch runner that processes all audio files in data/inputs/, writes outputs to data/outputs/, and supports resume on failure.\n\nAcceptance Criteria:\n- [ ] scripts/batch_transcribe.(ps1|sh) with --model-size, --diarization (whisperx|alt|off), --preprocess flags\n- [ ] Skips already-completed files; writes a manifest CSV with status, duration, RTF, WER (if reference available)\n\nLabels: Area/Transcription, Type/feat\nPriority: P0\nDepends on: Audio preprocessing: denoise and silence trimming","number":9,"title":"Batch transcribe directory with resume capability"},{"body":"Add optional preprocessing for better WER: light denoise (DeepFilterNet or ffmpeg), loudnorm, optional HPF; trim long silences for faster processing.\n\nAcceptance Criteria:\n- [ ] pipeline/preprocess.py with --denoise, --loudnorm, --trim-silence options\n- [ ] Before/after examples and metrics recorded in benchmarks/\n\nLabels: Area/Transcription, Type/feat\nPriority: P1\nDepends on: Implement faster-whisper transcribe (GPU)","number":8,"title":"Audio preprocessing: denoise and silence trimming"},{"body":"Implement alternative diarization using embeddings + spectral clustering (e.g., Resemblyzer), for environments without HF token.\n\nAcceptance Criteria:\n- [ ] pipeline/diarize_alt.py <audio> yields (start,end,speaker,text)\n- [ ] Quality/limits documented in docs/diarization.md\n\nLabels: Area/Diarization, Type/feat\nPriority: P2\nDepends on: Add WhisperX alignment and pyannote diarization","number":7,"title":"Provide no-token diarization alternative"},{"body":"Integrate WhisperX alignment and pyannote diarization with speaker labels.\n\nAcceptance Criteria:\n- [ ] pipeline/diarize_whisperx.py <audio> emits JSON: segments[{start,end,speaker,text}]\n- [ ] Configurable VAD thresholds; fallback to CPU if GPU OOM\n- [ ] Docs on acquiring free HuggingFace token and model pulls\n\nLabels: Area/Diarization, Type/feat\nPriority: P0\nDepends on: Implement faster-whisper transcribe (GPU)","number":6,"title":"Add WhisperX alignment and pyannote diarization"},{"body":"Use faster-whisper (CTranslate2) for speed/VRAM efficiency. Implement a sanity transcribe on a short WAV.\n\nAcceptance Criteria:\n- [ ] pipeline/transcribe_fw.py <audio> outputs .txt and .json with word timestamps\n- [ ] --model-size selectable: base, small, medium.en, large-v3\n- [ ] GPU used by default; print realtime factor (RTF)\n\nLabels: Area/Transcription, Type/feat\nPriority: P0\nDepends on: Create Python environment and lock dependencies","number":5,"title":"Implement faster-whisper transcribe (GPU)"},{"body":"Create Python 3.10/3.11 env and pin versions for torch, torchaudio, faster-whisper, whisperx, pyannote-audio, numpy, soundfile, rich, tqdm, pydantic, ffmpeg-python.\n\nAcceptance Criteria:\n- [ ] environment.yml (conda) and requirements.txt (venv) present\n- [ ] scripts/make_env.(ps1|sh) to create/activate env across OSes\n- [ ] python -c \"import torch; print(torch.cuda.is_available())\" returns True on GPU boxes\n\nLabels: Area/Infra, Type/chore, OS/Windows, OS/Linux, OS/macOS\nPriority: P0\nDepends on: Install FFmpeg and add to PATH","number":4,"title":"Create Python environment and lock dependencies"},{"body":"Audio IO depends on FFmpeg. Provide commands for Win/Linux/macOS and verify installation.\n\nAcceptance Criteria:\n- [ ] ffmpeg -version works in shell & PowerShell\n- [ ] docs/prereqs.md lists install steps for all OSes\n\nLabels: Area/Infra, Type/chore, OS/Windows, OS/Linux, OS/macOS\nPriority: P0\nDepends on: Verify NVIDIA drivers, CUDA runtime, and GPU visibility","number":3,"title":"Install FFmpeg and add to PATH"},{"body":"Detect GPUs and log driver/CUDA versions. Confirm both RTX 3060s are visible to PyTorch.\n\nAcceptance Criteria:\n- [ ] scripts/check_gpu.py prints torch.cuda.is_available(), torch.version.cuda, device count/names\n- [ ] Docs for Windows (NVIDIA driver), Linux (nvidia-driver + toolkit), macOS (CPU-only path)\n- [ ] Troubleshooting section for common CUDA errors (driver mismatch, OOM, out-of-memory fragmentation)\n\nLabels: Area/Infra, Type/chore, Risk/Blocking, OS/Windows, OS/Linux\nPriority: P0\nDepends on: Initialize repo structure and decision log","number":2,"title":"Verify NVIDIA drivers, CUDA runtime, and GPU visibility"},{"body":"Create a clean repo skeleton suitable for a local, free transcription/diarization pipeline. Add a decision log and basic docs.\n\nAcceptance Criteria:\n- [ ] Folders: scripts/, pipeline/, data/inputs/, data/outputs/, docs/, benchmarks/\n- [ ] Files: README.md, DECISIONS.md, LICENSE, .gitignore\n- [ ] Document target: hour-long+ calls, multi-speaker, GPU-accelerated\n\nLabels: Area/Infra, Type/chore, OS/Windows, OS/Linux, OS/macOS\nPriority: P2","number":1,"title":"Initialize repo structure and decision log"}]
