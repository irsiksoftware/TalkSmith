# TalkSmith

> **Local, free, GPU-accelerated transcription and diarization pipeline for long-form multi-speaker audio**

TalkSmith is a comprehensive solution for transcribing and diarizing hour-long+ recordings with multiple speakersâ€”completely free and running entirely on your local hardware. Built for professionals who need accurate, speaker-labeled transcripts without recurring cloud costs or privacy concerns.

## ğŸ¯ What It Does

TalkSmith transforms your audio recordings into:
- **Accurate transcriptions** with word-level timestamps
- **Speaker diarization** (who said what and when)
- **Multiple export formats** (TXT, SRT, VTT, JSON)
- **Intelligent outlines** and summaries
- **Optional PRD/plan generation** from meeting transcripts

All powered by your local GPU(s), with support for multi-GPU parallelism to maximize throughput.

## ğŸ’° Cost Savings

TalkSmith replaces expensive cloud transcription services with a one-time setup that pays for itself quickly:

| Service | Cost (per hour) | 100 Hours | 1000 Hours |
|---------|----------------|-----------|------------|
| **Rev.ai** | $1.25 | $125 | $1,250 |
| **Otter.ai Business** | $0.83* | $83 | $830 |
| **AssemblyAI** | $0.65 | $65 | $650 |
| **Deepgram** | $0.43 | $43 | $430 |
| **AWS Transcribe** | $0.024/min | $144 | $1,440 |
| **TalkSmith** | **$0** | **$0** | **$0** |

*Based on business plan pricing amortized per hour

### Products Replaced

- **Otter.ai** - Meeting transcription with speaker labels
- **Rev.ai** - Professional transcription service
- **Descript** - Audio/video transcription and editing
- **AssemblyAI** - API-based speech-to-text
- **Deepgram** - Real-time and batch transcription
- **Sonix** - Automated transcription with timestamps
- **Trint** - Transcription for media professionals
- **Happy Scribe** - Transcription and subtitling

**ROI Example:** If you transcribe 20 hours/month, you'd save $780-$1,500 annually compared to cloud services. With TalkSmith, your only costs are electricity (~$2-5/month for GPU usage).

## âœ¨ Key Features

### Core Capabilities
- ğŸš€ **GPU-accelerated** transcription with faster-whisper (CTranslate2)
- ğŸ‘¥ **Speaker diarization** via WhisperX + pyannote.audio
- ğŸ™ï¸ **Multi-speaker support** for meetings, interviews, podcasts
- ğŸ“Š **Batch processing** with resume capability
- ğŸ”§ **Audio preprocessing** (denoise, loudnorm, silence trimming)
- ğŸ“ **Multiple export formats** (TXT, SRT, VTT, JSON)

### Advanced Features
- ğŸ’¾ **Multi-GPU parallelism** (utilize multiple RTX 3060s concurrently)
- ğŸ”„ **No-token diarization** alternative (no HuggingFace account required)
- ğŸ“‹ **Speaker normalization** and outline generation
- ğŸ”’ **PII scrubbing** for sensitive recordings
- â˜ï¸ **Optional cloud sync** (rclone to Google Drive)
- ğŸ“„ **PRD/plan generation** from meeting transcripts

### Privacy & Control
- âœ… **100% local processing** - your audio never leaves your machine
- âœ… **No API keys or subscriptions** required (except optional HF token for best diarization)
- âœ… **Open source** - full transparency and customization
- âœ… **Offline capable** - no internet required after initial setup

## ğŸ® Quick Start

### Prerequisites
- **GPU:** NVIDIA GPU with CUDA support (tested on dual RTX 3060s, 12GB VRAM each)
- **OS:** Windows, Linux, or macOS (CPU-only mode on macOS)
- **Python:** 3.10 or 3.11
- **FFmpeg:** Required for audio processing

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/DakotaIrsik/TalkSmith.git
cd TalkSmith

# 2. Create environment (Windows PowerShell)
.\scripts\make_env.ps1

# 2. Create environment (Linux/macOS)
./scripts\make_env.sh

# 3. Verify GPU setup
python scripts/check_gpu.py

# 4. (Optional) Prefetch models
.\scripts\prefetch_models.ps1 --sizes medium.en,large-v3
```

### Basic Usage

```bash
# Transcribe a single file
python pipeline/transcribe_fw.py path/to/audio.wav --model-size medium.en

# Transcribe with diarization
python pipeline/diarize_whisperx.py path/to/audio.wav

# Batch process a directory
.\scripts\batch_transcribe.ps1 --model-size large-v3 --diarization whisperx

# Generate outline from transcript
python pipeline/outline_from_segments.py path/to/segments.json
```

### Using the CLI

```bash
# Unified CLI interface (coming soon)
python cli/main.py transcribe --input audio.wav --diarize --export srt,json
python cli/main.py batch --input-dir ./recordings --model large-v3
python cli/main.py plan --segments segments.json --output plan.md
```

## ğŸ—ï¸ Architecture

```
TalkSmith/
â”œâ”€â”€ pipeline/           # Core processing modules
â”‚   â”œâ”€â”€ transcribe_fw.py       # faster-whisper transcription
â”‚   â”œâ”€â”€ diarize_whisperx.py    # WhisperX + pyannote diarization
â”‚   â”œâ”€â”€ diarize_alt.py         # No-token alternative diarization
â”‚   â”œâ”€â”€ preprocess.py          # Audio preprocessing
â”‚   â”œâ”€â”€ postprocess_speakers.py # Speaker normalization
â”‚   â””â”€â”€ outline_from_segments.py # Outline generation
â”œâ”€â”€ scripts/            # Automation and utilities
â”‚   â”œâ”€â”€ batch_transcribe.ps1   # Batch processing (Windows)
â”‚   â”œâ”€â”€ batch_transcribe.sh    # Batch processing (Linux)
â”‚   â”œâ”€â”€ launcher.ps1/sh        # Multi-GPU job scheduler
â”‚   â””â”€â”€ check_gpu.py           # GPU verification
â”œâ”€â”€ cli/                # Unified CLI interface
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ inputs/         # Place audio files here
â”‚   â”œâ”€â”€ outputs/        # Transcripts and exports
â”‚   â””â”€â”€ samples/        # Test samples
â”œâ”€â”€ docs/               # Documentation
â”œâ”€â”€ benchmarks/         # Performance benchmarks
â””â”€â”€ tests/              # Unit and E2E tests
```

## ğŸ”§ Configuration

All settings are centralized in `settings.ini`:

```ini
[Paths]
input_dir = data/inputs
output_dir = data/outputs

[Models]
whisper_model = large-v3
diarization_model = pyannote/speaker-diarization

[Diarization]
mode = whisperx  # whisperx, alt, or off
vad_threshold = 0.5

[Export]
formats = txt,json,srt
```

Override via environment variables or CLI flags:
```bash
WHISPER_MODEL=medium.en python pipeline/transcribe_fw.py audio.wav
```

## ğŸ“Š Performance

Benchmarks on dual RTX 3060 setup (12GB VRAM each):

| Audio Length | Model | Single GPU RTF* | Dual GPU RTF* | Speedup |
|--------------|-------|----------------|---------------|---------|
| 60 min | medium.en | 0.12 | 0.06 | 2.0x |
| 60 min | large-v3 | 0.21 | 0.11 | 1.9x |
| 120 min | large-v3 | 0.21 | 0.11 | 1.9x |

*RTF = Real-Time Factor (lower is faster). RTF of 0.12 means 60 minutes processes in ~7 minutes.

## ğŸ¯ Use Cases

- **Product Managers:** Transcribe customer interviews and generate PRDs
- **Researchers:** Analyze interview data with speaker attribution
- **Content Creators:** Subtitle podcasts and videos
- **Journalists:** Transcribe interviews and press conferences
- **Students:** Transcribe lectures with speaker identification
- **Legal/Medical:** Transcribe depositions/consultations (with PII scrubbing)

## ğŸ›£ï¸ Roadmap

See our [GitHub Issues](https://github.com/DakotaIrsik/TalkSmith/issues) for detailed planning:

**Phase 1: Foundation (P0)**
- [x] Repository structure and documentation
- [ ] GPU and CUDA verification
- [ ] Python environment setup
- [ ] Core transcription pipeline (faster-whisper)
- [ ] Diarization (WhisperX + pyannote)
- [ ] Batch processing with resume
- [ ] Export formats

**Phase 2: Enhancement (P1)**
- [ ] Audio preprocessing (denoise, trim)
- [ ] Multi-GPU parallelism
- [ ] Speaker post-processing and outlines
- [ ] CLI wrapper
- [ ] Comprehensive testing

**Phase 3: Advanced (P2)**
- [ ] Alternative diarization (no HF token)
- [ ] Benchmark suite
- [ ] Google Drive sync
- [ ] Plan/PRD generation
- [ ] Docker (CUDA) support
- [ ] PII scrubbing

## ğŸ¤ Contributing

We welcome contributions! Please read our [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines on:
- Setting up your development environment
- Code style and standards
- Testing requirements
- Pull request process

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

Built on the shoulders of giants:
- **faster-whisper** by Guillaume Klein (CTranslate2-optimized Whisper)
- **WhisperX** by Max Bain (alignment and diarization)
- **pyannote.audio** by HervÃ© Bredin (speaker diarization)
- **OpenAI Whisper** (original ASR model)

## ğŸ“ Support

- ğŸ› **Issues:** [GitHub Issues](https://github.com/DakotaIrsik/TalkSmith/issues)
- ğŸ’¬ **Discussions:** [GitHub Discussions](https://github.com/DakotaIrsik/TalkSmith/discussions)
- ğŸ“– **Docs:** [docs/](docs/)

---

**Made with â¤ï¸ for developers who value privacy, control, and zero recurring costs.**
